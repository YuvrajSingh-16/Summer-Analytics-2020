{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "----------\n",
    "**IBM Attrition Analysis and Prediction**\n",
    "=====================================\n",
    "\n",
    "***XGB : CV - Accuracy (5 folds) =  .891***\n",
    "\n",
    "***Vincent Lugat***\n",
    "\n",
    "*October 2018*\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21c1be5c32b1987bff4d827804778f1db54a23c6"
   },
   "source": [
    "![](http://image.noelshack.com/fichiers/2018/41/1/1539014632-1-bye.png)\n",
    "\n",
    "source : http://thecontextofthings.com/2017/01/06/employee-attrition/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c05d96007d517ef7c498690daed5a9b80db645c0"
   },
   "source": [
    "- <a href='#1'>1. Load libraries and read the data</a>  \n",
    "    - <a href='#1.1'>1.1. Load libraries</a> \n",
    "    - <a href='#1.2'>1.2. Read the data</a> \n",
    "    - <a href='#1.3'>1.3. Missing values</a> \n",
    "    - <a href='#1.4'>1.4. Reassign target and drop useless features</a> \n",
    "- <a href='#2'>2. Exploratory Data Analysis (EDA)</a> \n",
    "    - <a href='#2.1'>2.1. Head and describe</a> \n",
    "    - <a href='#2.2'>2.2. Target distribution (number and %)</a> \n",
    "    - <a href='#2.3'>2.3. Features distribution and barplot (hue = Attrition)</a> \n",
    "    - <a href='#2.4'>2.4. Pie plot and barplot</a> \n",
    "- <a href='#3'>3. Feature engineering and selection</a>\n",
    "    - <a href='#3.1'>3.1. New features (24) </a> \n",
    "    - <a href='#3.2'>3.2. Drop some features</a> \n",
    "    - <a href='#3.3'>3.3. Features encoding and scaling</a>\n",
    "    - <a href='#3.4'>3.4. Correlation Matrix</a>\n",
    "    - <a href='#3.5'>3.5. Remove collinear features</a>\n",
    "- <a href='#4'>4. Define functions</a>\n",
    "    - <a href='#4.1'>4.1. Define model performance plot </a> \n",
    "    - <a href='#4.2'>4.2. Define feature importance plot </a> \n",
    "    - <a href='#4.3'>4.3. Define cumulative gains curve</a>\n",
    "    - <a href='#4.4'>4.4. Define cross validation metrics</a>\n",
    "- <a href='#5'>5. Prepare dataset</a>\n",
    "    - <a href='#5.1'>5.1. Define (X,  y)</a> \n",
    "    - <a href='#5.2'>5.2. Train test split</a> \n",
    "- <a href='#6'>6. XGBoost - RandomizedSearchCV to optimize hyperparameters (800 comb)</a> \n",
    "\n",
    "- <a href='#7'>7. XGBoost - With best hyperparameters = 89.11</a>\n",
    "    - <a href='#7.1'>7.1. XGBoost - Modeling and performance plot</a> \n",
    "    - <a href='#7.2'>7.2. XGBoost - Feature importance </a> \n",
    "    - <a href='#7.3'>7.3. XGBoost - Cumulative gains curve</a> \n",
    "    - <a href='#7.4'>7.4. XGBoost - Cross validation (5 folds)</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2a6a17180340827442bbd04fd673376388d0826"
   },
   "source": [
    "# <a id='1'>1. Load libraries and read the data</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f23306927fb09ce1eab26c6d36b9f70f62783dd6"
   },
   "source": [
    "## <a id='1.1'>1.1. Load libraries</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "e747c5e20f9fd17baff29a26b302a86638c700f3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d60412692062>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve, train_test_split\n",
    "from sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c97342a31c13633a60e206be88f80db3e25fbce"
   },
   "source": [
    "## <a id='1.2'>1.2. Read the data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3768ada4565e9354e814b7ff978270fa86dee61"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e10bd81750d48d6fa1efaff7bfd657bbf956b442"
   },
   "source": [
    "## <a id='1.3'>1.3. Missing values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e4e64be3951b9e7bcd57eb4a7ddad37773dfd51"
   },
   "outputs": [],
   "source": [
    "null_feat = pd.DataFrame(len(data['Attrition']) - data.isnull().sum(), columns = ['Count'])\n",
    "\n",
    "trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, marker=dict(color = 'lightgrey',\n",
    "        line=dict(color='#000000',width=1.5)))\n",
    "\n",
    "layout = dict(title =  \"Missing Values\")\n",
    "                    \n",
    "fig = dict(data = [trace], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7606cecfcf02bf329bbeba4b94701cb59f82b44"
   },
   "source": [
    "## <a id='1.4'>1.4. Reassign target and drop useless features</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ebb3d71ba18c719c7ea5e8b309a058672bc582"
   },
   "outputs": [],
   "source": [
    "# Reassign target\n",
    "data.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)\n",
    "# Drop useless feat\n",
    "data = data.drop(columns=['StandardHours', \n",
    "                          'EmployeeCount', \n",
    "                          'Over18',\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "963bdedb797062249197b1a13683010631f51f06"
   },
   "source": [
    "# <a id='2'>2. Exploratory Data Analysis (EDA)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "383644d56422567306ab05e6f12b05b764e778a8"
   },
   "source": [
    "## <a id='2.1'>2.1. Head and describe</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "248f53119c5c080364151bfefed47f77d1319e5d"
   },
   "outputs": [],
   "source": [
    "# head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "705f70983fc75e0db96ab97e851c32e53d51092f"
   },
   "outputs": [],
   "source": [
    "# describe\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a99febaf823220027a167ae6cedec751657a1e1"
   },
   "source": [
    "## <a id='2.2'>2.2. Target distribution (number and %)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74ad8bfadf7fb6a0fdc4c1b34c57d707c9692af5"
   },
   "outputs": [],
   "source": [
    "attrition = data[(data['Attrition'] != 0)]\n",
    "no_attrition = data[(data['Attrition'] == 0)]\n",
    "\n",
    "#------------COUNT-----------------------\n",
    "trace = go.Bar(x = (len(attrition), len(no_attrition)), y = ['Yes_attrition', 'No_attrition'], orientation = 'h', opacity = 0.8, marker=dict(\n",
    "        color=['gold', 'lightskyblue'],\n",
    "        line=dict(color='#000000',width=1.5)))\n",
    "\n",
    "layout = dict(title =  'Count of attrition variable')\n",
    "\n",
    "fig = dict(data = [trace], layout=layout)\n",
    "py.iplot(fig)\n",
    "\n",
    "#------------PERCENTAGE-------------------\n",
    "trace = go.Pie(labels = ['No_attrition', 'Yes_attrition'], values = data['Attrition'].value_counts(), \n",
    "               textfont=dict(size=15), opacity = 0.8,\n",
    "               marker=dict(colors=['lightskyblue','gold'], \n",
    "                           line=dict(color='#000000', width=1.5)))\n",
    "\n",
    "\n",
    "layout = dict(title =  'Distribution of attrition variable')\n",
    "           \n",
    "fig = dict(data = [trace], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d27ccfbebae0c3f707298c3d5b3cf3cc41ecef1"
   },
   "source": [
    "## <a id='2.3'>2.3. Features distribution and barplot (hue = Attrition)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f13f26c190b15d9b1fe64dfbdb660e5c5ebbc50"
   },
   "outputs": [],
   "source": [
    "def plot_distribution(var_select, bin_size) : \n",
    "# Calculate the correlation coefficient between the new variable and the target\n",
    "    corr = data['Attrition'].corr(data[var_select])\n",
    "    corr = np.round(corr,3)\n",
    "    tmp1 = attrition[var_select]\n",
    "    tmp2 = no_attrition[var_select]\n",
    "    hist_data = [tmp1, tmp2]\n",
    "    \n",
    "    group_labels = ['Yes_attrition', 'No_attrition']\n",
    "    colors = ['#FFD700', '#7EC0EE']\n",
    "\n",
    "    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, curve_type='kde', bin_size = bin_size)\n",
    "    \n",
    "    fig['layout'].update(title = var_select+' '+'(corr target ='+ str(corr)+')')\n",
    "\n",
    "    py.iplot(fig, filename = 'Density plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ef21a5944ac7c3939631417292ae17cc586c6a4"
   },
   "outputs": [],
   "source": [
    "def barplot(var_select, x_no_numeric) :\n",
    "    tmp1 = data[(data['Attrition'] != 0)]\n",
    "    tmp2 = data[(data['Attrition'] == 0)]\n",
    "    tmp3 = pd.DataFrame(pd.crosstab(data[var_select],data['Attrition']), )\n",
    "    tmp3['Attr%'] = tmp3[1] / (tmp3[1] + tmp3[0]) * 100\n",
    "    if x_no_numeric == True  : \n",
    "        tmp3 = tmp3.sort_values(1, ascending = False)\n",
    "\n",
    "    color=['lightskyblue','gold' ]\n",
    "    trace1 = go.Bar(\n",
    "        x=tmp1[var_select].value_counts().keys().tolist(),\n",
    "        y=tmp1[var_select].value_counts().values.tolist(),\n",
    "        name='Yes_Attrition',opacity = 0.8, marker=dict(\n",
    "        color='gold',\n",
    "        line=dict(color='#000000',width=1)))\n",
    "\n",
    "    \n",
    "    trace2 = go.Bar(\n",
    "        x=tmp2[var_select].value_counts().keys().tolist(),\n",
    "        y=tmp2[var_select].value_counts().values.tolist(),\n",
    "        name='No_Attrition', opacity = 0.8, marker=dict(\n",
    "        color='lightskyblue',\n",
    "        line=dict(color='#000000',width=1)))\n",
    "    \n",
    "    trace3 =  go.Scatter(   \n",
    "        x=tmp3.index,\n",
    "        y=tmp3['Attr%'],\n",
    "        yaxis = 'y2',\n",
    "        name='% Attrition', opacity = 0.6, marker=dict(\n",
    "        color='black',\n",
    "        line=dict(color='#000000',width=0.5\n",
    "        )))\n",
    "\n",
    "    layout = dict(title =  str(var_select),\n",
    "              xaxis=dict(), \n",
    "              yaxis=dict(title= 'Count'), \n",
    "              yaxis2=dict(range= [-0, 75], \n",
    "                          overlaying= 'y', \n",
    "                          anchor= 'x', \n",
    "                          side= 'right',\n",
    "                          zeroline=False,\n",
    "                          showgrid= False, \n",
    "                          title= '% Attrition'\n",
    "                         ))\n",
    "    \n",
    "    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86fdc54cc7f24aecb49361bb76c5f9701c193627"
   },
   "outputs": [],
   "source": [
    "plot_distribution('Age', False)\n",
    "barplot('Age', False)\n",
    "plot_distribution('DailyRate', 100)\n",
    "plot_distribution('DistanceFromHome', False)\n",
    "barplot('DistanceFromHome', False)\n",
    "plot_distribution('HourlyRate', False)\n",
    "plot_distribution('MonthlyIncome', 100)\n",
    "plot_distribution('MonthlyRate', 100)\n",
    "plot_distribution('NumCompaniesWorked', False)\n",
    "barplot('NumCompaniesWorked',False)\n",
    "plot_distribution('PercentSalaryHike', False)\n",
    "barplot('PercentSalaryHike', False) \n",
    "plot_distribution('TotalWorkingYears', False)\n",
    "barplot('TotalWorkingYears', False)\n",
    "plot_distribution('TrainingTimesLastYear', False)\n",
    "barplot('TrainingTimesLastYear',False)\n",
    "plot_distribution('YearsAtCompany', False)\n",
    "barplot('YearsAtCompany', False)\n",
    "plot_distribution('YearsInCurrentRole', False)\n",
    "barplot('YearsInCurrentRole', False)\n",
    "plot_distribution('YearsSinceLastPromotion', False)\n",
    "barplot('YearsSinceLastPromotion', False)\n",
    "plot_distribution('YearsWithCurrManager', False)\n",
    "barplot('YearsWithCurrManager', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c60c19375138e16aebe02bcebef7bec18b245061"
   },
   "source": [
    "## <a id='2.4'>2.4. Pie plot and barplot</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "921f00f9fb0b5b5e17faae8d0e806b93a1a70779"
   },
   "outputs": [],
   "source": [
    "def plot_pie(var_select) :\n",
    "    \n",
    "    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue', 'lightgrey', 'orange', 'white', 'lightpink']\n",
    "    trace1 = go.Pie(values  = attrition[var_select].value_counts().values.tolist(),\n",
    "                    labels  = attrition[var_select].value_counts().keys().tolist(),\n",
    "                    textfont=dict(size=15), opacity = 0.8,\n",
    "                    hoverinfo = \"label+percent+name\",\n",
    "                    domain  = dict(x = [0,.48]),\n",
    "                    name    = \"attrition employes\",\n",
    "                    marker  = dict(colors = colors, line = dict(width = 1.5)))\n",
    "    trace2 = go.Pie(values  = no_attrition[var_select].value_counts().values.tolist(),\n",
    "                    labels  = no_attrition[var_select].value_counts().keys().tolist(),\n",
    "                    textfont=dict(size=15), opacity = 0.8,\n",
    "                    hoverinfo = \"label+percent+name\",\n",
    "                    marker  = dict(colors = colors, line = dict(width = 1.5)),\n",
    "                    domain  = dict(x = [.52,1]),\n",
    "                    name    = \"Non attrition employes\" )\n",
    "\n",
    "    layout = go.Layout(dict(title = var_select + \" distribution in employes attrition \",\n",
    "                            annotations = [dict(text = \"Yes_attrition\",\n",
    "                                                font = dict(size = 13),\n",
    "                                                showarrow = False,\n",
    "                                                x = .22, y = -0.1),\n",
    "                                            dict(text = \"No_attrition\",\n",
    "                                                font = dict(size = 13),\n",
    "                                                showarrow = False,\n",
    "                                                x = .8,y = -.1)]))\n",
    "                                          \n",
    "\n",
    "    fig  = go.Figure(data = [trace1,trace2],layout = layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6899ff7a536c2d86543e81eeb57a08ddd38de8c2"
   },
   "outputs": [],
   "source": [
    "plot_pie(\"Gender\")\n",
    "barplot('Gender',True)\n",
    "plot_pie('OverTime')\n",
    "barplot('OverTime',True)\n",
    "plot_pie('BusinessTravel')\n",
    "barplot('BusinessTravel',True)\n",
    "plot_pie('JobRole')\n",
    "barplot('JobRole',True)\n",
    "plot_pie('Department') \n",
    "barplot('Department',True)\n",
    "plot_pie('MaritalStatus') \n",
    "barplot('MaritalStatus',True)\n",
    "plot_pie('EducationField') \n",
    "barplot('EducationField',True)\n",
    "plot_pie('Education') \n",
    "barplot('Education',False)\n",
    "plot_pie('EnvironmentSatisfaction')\n",
    "barplot('EnvironmentSatisfaction',False)\n",
    "plot_pie('JobInvolvement')\n",
    "barplot('JobInvolvement', False)\n",
    "plot_pie('JobLevel')\n",
    "barplot('JobLevel',False)\n",
    "plot_pie('JobSatisfaction')\n",
    "barplot('JobSatisfaction',False)\n",
    "plot_pie('PerformanceRating')\n",
    "barplot('PerformanceRating',False)\n",
    "plot_pie('RelationshipSatisfaction')\n",
    "barplot('RelationshipSatisfaction', False)\n",
    "plot_pie('StockOptionLevel')\n",
    "barplot('StockOptionLevel', False)\n",
    "plot_pie('WorkLifeBalance')\n",
    "barplot('WorkLifeBalance', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec03ef2f78d489945b25a265c01b4a72a23cda92"
   },
   "source": [
    "# <a id='3'>3. Feature engineering and selection</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88fcd7e83d07e99f02263b07eb5ef87371290160"
   },
   "source": [
    "## <a id='3.1'>3.1. New features : 24</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c9de44eabebe4bed64a973fe66bebfec99f7bc2"
   },
   "outputs": [],
   "source": [
    "def SalesDpt(data) :\n",
    "    if data['Department'] == 'Sales':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['SalesDpt'] = data.apply(lambda data:SalesDpt(data) ,axis = 1)\n",
    "\n",
    "def JobInvCut(data) :\n",
    "    if data['JobInvolvement'] < 2.5 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['JobInvCut'] = data.apply(lambda data:JobInvCut(data) ,axis = 1)\n",
    "\n",
    "def MiddleTraining(data) :\n",
    "    if data['TrainingTimesLastYear'] >= 3 and data['TrainingTimesLastYear'] <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['MiddleTraining'] = data.apply(lambda data:MiddleTraining(data) ,axis = 1)\n",
    "\n",
    "def MoovingPeople(data) :\n",
    "    if data['NumCompaniesWorked'] > 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['MoovingPeople'] = data.apply(lambda data:MoovingPeople(data), axis = 1)\n",
    "\n",
    "data['TotalSatisfaction_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction'] + data['JobSatisfaction'] + data['JobInvolvement'] + data['WorkLifeBalance'])/5\n",
    "\n",
    "def NotSatif(data) : \n",
    "    if  data['TotalSatisfaction_mean'] < 2.35 :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['NotSatif'] = data.apply(lambda data:NotSatif(data) ,axis = 1)\n",
    "\n",
    "def LongDisWL1(data) : \n",
    "    if  data['DistanceFromHome'] > 11 and data['WorkLifeBalance'] == 1 :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['LongDisWL1'] = data.apply(lambda data:LongDisWL1(data) ,axis = 1)\n",
    "\n",
    "def LongDis(data) : \n",
    "    if  data['DistanceFromHome'] > 11:\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['LongDis'] = data.apply(lambda data:LongDis(data) ,axis = 1)\n",
    "\n",
    "def LongDisJobS1(data) : \n",
    "    if  data['DistanceFromHome'] > 11 and data['JobSatisfaction'] == 1 :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['LongDisJobS1'] = data.apply(lambda data:LongDisJobS1(data) ,axis = 1)\n",
    "\n",
    "def LongDisJL1(data) : \n",
    "    if  data['DistanceFromHome'] > 11 and data['JobLevel'] == 1 :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['LongDisJL1'] = data.apply(lambda data:LongDisJL1(data) ,axis = 1)\n",
    "\n",
    "def ShortDisNotSingle(data) : \n",
    "    if  data['MaritalStatus'] != 'Single' and data['DistanceFromHome'] < 5:\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['ShortDisNotSingle'] = data.apply(lambda data:ShortDisNotSingle(data) ,axis = 1)\n",
    "\n",
    "def LongDisSingle(data) : \n",
    "    if  data['MaritalStatus'] == 'Single' and data['DistanceFromHome'] > 11:\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['LongDisSingle'] = data.apply(lambda data:LongDisSingle(data) ,axis = 1)\n",
    "\n",
    "def Engaged(data) : \n",
    "    if data['Age'] > 35 and data['MaritalStatus'] != 'Single':\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['Engaged'] = data.apply(lambda data:Engaged(data) ,axis = 1)\n",
    "\n",
    "def YoungAndBadPaid(data) : \n",
    "    if data['Age'] < 35 and data['Age'] > 23 and (data['MonthlyIncome'] < 3500):\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['YoungAndBadPaid'] = data.apply(lambda data:YoungAndBadPaid(data) ,axis = 1)\n",
    "\n",
    "def YoungNeverEngaged(data) : \n",
    "    if data['Age'] < 24 and data['MaritalStatus'] == 'Single' :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "data['YoungNeverEngaged'] = data.apply(lambda data:YoungNeverEngaged(data) ,axis = 1)\n",
    "\n",
    "data['Time_in_each_comp'] = (data['Age'] - 20) / ((data)['NumCompaniesWorked'] + 1)\n",
    "data['RelSatisf_mean'] = (data['RelationshipSatisfaction']  + data['EnvironmentSatisfaction']) / 2\n",
    "data['JobSatisf_mean'] = (data['JobSatisfaction'] + data['JobInvolvement']) / 2\n",
    "data['Income_Distance'] = data['MonthlyIncome'] / data['DistanceFromHome']\n",
    "data['Hrate_Mrate'] = data['HourlyRate'] / data['MonthlyRate']\n",
    "data['Stability'] = data['YearsInCurrentRole'] / data['YearsAtCompany']\n",
    "data['Stability'].fillna((data['Stability'].mean()), inplace=True)\n",
    "data['Income_YearsComp'] = data['MonthlyIncome'] / data['YearsAtCompany']\n",
    "data['Income_YearsComp'] = data['Income_YearsComp'].replace(np.Inf, 0)\n",
    "data['Fidelity'] = (data['NumCompaniesWorked']) / data['TotalWorkingYears']\n",
    "data['Fidelity'] = data['Fidelity'].replace(np.Inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1b486fb7a9d45bb654a4f338055d64326856428"
   },
   "outputs": [],
   "source": [
    "barplot('Engaged', False)\n",
    "barplot('YoungAndBadPaid', False)\n",
    "barplot('YoungNeverEngaged', False)\n",
    "barplot('LongDisSingle', False)\n",
    "barplot('LongDisJL1', False)\n",
    "barplot('ShortDisNotSingle', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fc41e99382306b741084e2a46a90aefcba6b422"
   },
   "source": [
    "## <a id='3.2'>3.2. Drop some features</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc12dc2e387797ad03743b6d2c021ff6fc3dbdd1"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\n",
    "                        'Age',\n",
    "                        'MonthlyIncome',\n",
    "                        'YearsAtCompany',\n",
    "                        'DistanceFromHome',\n",
    "                        'PerformanceRating',\n",
    "                        'NumCompaniesWorked'\n",
    "                     ])\n",
    "\n",
    "print (\"\\nMissing values :  \", data.isnull().sum().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bc8fb27e5778aac4225dcb71e8f219f0cf9d8d3"
   },
   "source": [
    "## <a id='3.3'>3.3. Features encoding and scaling</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb6db23a0f250b5e128fa77e34ce20b3f9340a89"
   },
   "outputs": [],
   "source": [
    "#customer id col\n",
    "Id_col     = ['EmployeeNumber']\n",
    "#Target columns\n",
    "target_col = [\"Attrition\"]\n",
    "#categorical columns\n",
    "cat_cols   = data.nunique()[data.nunique() < 10].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in data.columns if x not in cat_cols + target_col + Id_col]\n",
    "#Binary columns with 2 values\n",
    "bin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n",
    "#Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "#Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "    \n",
    "#Duplicating columns for multi value columns\n",
    "data = pd.get_dummies(data = data,columns = multi_cols )\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(data[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_data_og = data.copy()\n",
    "data = data.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "data = data.drop(['EmployeeNumber'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa59bc1ff371813a16e207ec5751a4dfa1cfbadd"
   },
   "source": [
    "## <a id='3.4'>3.4. Correlation Matrix</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42c618f0e8862a67f1197fc865fea3186febc992"
   },
   "outputs": [],
   "source": [
    "#correlation\n",
    "correlation = data.corr()\n",
    "#tick labels\n",
    "matrix_cols = correlation.columns.tolist()\n",
    "#convert to array\n",
    "corr_array  = np.array(correlation)\n",
    "\n",
    "#Plotting\n",
    "trace = go.Heatmap(z = corr_array,\n",
    "                   x = matrix_cols,\n",
    "                   y = matrix_cols,\n",
    "                   colorscale='Viridis',\n",
    "                   colorbar   = dict() ,\n",
    "                  )\n",
    "layout = go.Layout(dict(title = 'Correlation Matrix for variables',\n",
    "                        autosize = False,\n",
    "                        #height  = 1400,\n",
    "                        #width   = 1600,\n",
    "                        margin  = dict(r = 0 ,l = 210,\n",
    "                                       t = 25,b = 210,\n",
    "                                     ),\n",
    "                        yaxis   = dict(tickfont = dict(size = 9)),\n",
    "                        xaxis   = dict(tickfont = dict(size = 9)),\n",
    "                       )\n",
    "                  )\n",
    "fig = go.Figure(data = [trace],layout = layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffeded839d00de6506547f849d5c1fcccc39a1c9"
   },
   "source": [
    "## <a id='3.5'>3.5. Remove collinear features</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32fd969262e3eb2d3f1c1dd97d0f3b358e215b4c"
   },
   "outputs": [],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.8\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "corr_matrix.head()\n",
    "\n",
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()\n",
    "\n",
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove :' % (len(to_drop)))\n",
    "\n",
    "data = data.drop(columns = to_drop)\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2d75c810daf8d0c487fe294f0c5f0919ffdfc23"
   },
   "source": [
    "# <a id='4'>4. Define functions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03fef192a42eb24829fd985f13bf3e5c20986293"
   },
   "source": [
    "## <a id='4.1'>4.1. Define model performance plot</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6e86485b204eefa2337023a4d30d4074f887a30"
   },
   "outputs": [],
   "source": [
    "def model_performance_plot(model) : \n",
    "    #conf matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n",
    "                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n",
    "                        colorscale = 'Viridis', showscale  = False)\n",
    "\n",
    "    #show metrics\n",
    "    tp = conf_matrix[1,1]\n",
    "    fn = conf_matrix[1,0]\n",
    "    fp = conf_matrix[0,1]\n",
    "    tn = conf_matrix[0,0]\n",
    "    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n",
    "    Precision =  (tp/(tp+fp))\n",
    "    Recall    =  (tp/(tp+fn))\n",
    "    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n",
    "\n",
    "    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n",
    "    show_metrics = show_metrics.T\n",
    "\n",
    "    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n",
    "    trace2 = go.Bar(x = (show_metrics[0].values), \n",
    "                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n",
    "                    textposition = 'auto',\n",
    "                   orientation = 'h', opacity = 0.8,marker=dict(\n",
    "            color=colors,\n",
    "            line=dict(color='#000000',width=1.5)))\n",
    "    \n",
    "    #plot roc curve\n",
    "    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n",
    "    fpr, tpr, t = roc_curve(y_test, y_score)\n",
    "    trace3 = go.Scatter(x = fpr,y = tpr,\n",
    "                        name = \"Roc : \",\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n",
    "    trace4 = go.Scatter(x = [0,1],y = [0,1],\n",
    "                        line = dict(color = ('black'),width = 1.5,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    # Precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    trace5 = go.Scatter(x = recall, y = precision,\n",
    "                        name = \"Precision\" + str(precision),\n",
    "                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n",
    "    \n",
    "    #subplots\n",
    "    fig = tls.make_subplots(rows=2, cols=2, print_grid=False, \n",
    "                        subplot_titles=('Confusion Matrix',\n",
    "                                        'Metrics',\n",
    "                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n",
    "                                        'Precision - Recall curve'))\n",
    "    \n",
    "    fig.append_trace(trace1,1,1)\n",
    "    fig.append_trace(trace2,1,2)\n",
    "    fig.append_trace(trace3,2,1)\n",
    "    fig.append_trace(trace4,2,1)\n",
    "    fig.append_trace(trace5,2,2)\n",
    "    \n",
    "    fig['layout'].update(showlegend = False, title = '<b>Model performance</b><br>'+str(model),\n",
    "                        autosize = False, height = 900,width = 830,\n",
    "                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        margin = dict(b = 195))\n",
    "    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n",
    "    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n",
    "    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n",
    "    fig.layout.titlefont.size = 14\n",
    "    \n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af404ccf3dcda5bcb56df94f23130beeff42ae0c"
   },
   "source": [
    "## <a id='4.2'>4.2. Define feature importance plot</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58d0d4c7f2d3c0c685368e4036f09d6b47532887"
   },
   "outputs": [],
   "source": [
    "def features_imp(model, cf) : \n",
    "\n",
    "    coefficients  = pd.DataFrame(model.feature_importances_)\n",
    "    column_data     = pd.DataFrame(list(data))\n",
    "    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n",
    "    trace = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_sumry[\"coefficients\"],\n",
    "                                  colorscale = \"Viridis\",\n",
    "                                  line = dict(width = .6,color = \"black\")))\n",
    "    layout = dict(title =  'Feature Importances xgb_cfl')\n",
    "                    \n",
    "    fig = dict(data = [trace], layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e8ab5de083f6b73358e0d8c5c6890f8fba28e84"
   },
   "source": [
    "## <a id='4.3'>4.3. Define cumulative gains curve</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "427a09623dfc0ae849224ba32d32ecb9776d5a98"
   },
   "outputs": [],
   "source": [
    "#cumulative gain curve\n",
    "def cum_gains_curve(model):\n",
    "    pos = pd.get_dummies(y_test).as_matrix()\n",
    "    pos = pos[:,1] \n",
    "    npos = np.sum(pos)\n",
    "    index = np.argsort(y_score) \n",
    "    index = index[::-1] \n",
    "    sort_pos = pos[index]\n",
    "    #cumulative sum\n",
    "    cpos = np.cumsum(sort_pos) \n",
    "    #recall\n",
    "    recall = cpos/npos \n",
    "    #size obs test\n",
    "    n = y_test.shape[0] \n",
    "    size = np.arange(start=1,stop=369,step=1) \n",
    "    #proportion\n",
    "    size = size / n \n",
    "    #plots\n",
    "    model = 'xgb_cfl'\n",
    "    trace1 = go.Scatter(x = size,y = recall,\n",
    "                        name = \"Lift curve\",\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n",
    "    trace2 = go.Scatter(x = size,y = size,\n",
    "                        name = \"Baseline\",\n",
    "                        showlegend=False,\n",
    "                        line = dict(color = ('black'),width = 1.5,\n",
    "                        dash = 'dot'))\n",
    "\n",
    "    layout = dict(title = 'Cumulative gains curve'+' '+str(model),\n",
    "                  yaxis = dict(title = 'Percentage positive targeted',zeroline = False),\n",
    "                  xaxis = dict(title = 'Percentage contacted', zeroline = False)\n",
    "                 )\n",
    "\n",
    "    fig  = go.Figure(data = [trace1,trace2], layout = layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2acadd1870360a727485fdeb2a8af0115458f7a9"
   },
   "source": [
    "## <a id='4.4'>4.4. Define cross validation metrics</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c64cc90dcef8c8f7046f510bad33e5e5d56af062"
   },
   "outputs": [],
   "source": [
    "# Cross val metric\n",
    "def cross_val_metrics(model) :\n",
    "    scores = ['accuracy', 'precision', 'recall']\n",
    "    for sc in scores:\n",
    "        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n",
    "        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aafb162df41b9a71fa7ecb2e0cd8750812dc0579"
   },
   "source": [
    "# <a id='5'>5. Prepare dataset</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c19355d7890d0b32d532294948fffe20c7c5b31d"
   },
   "source": [
    "## <a id='5.1'>5.1. Define (X, y)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e169cfa2ed00779a2f64ec2be421d91b18c12643"
   },
   "outputs": [],
   "source": [
    "# Def X and Y\n",
    "y = np.array(data.Attrition.tolist())\n",
    "data = data.drop('Attrition', 1)\n",
    "X = np.array(data.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d83599730eebf224cdadde69944f98002296e835"
   },
   "source": [
    "## <a id='5.2'>5.2. Train test split</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69294fae2584c2719ffc8a8f2068f2cf84b0c6df"
   },
   "outputs": [],
   "source": [
    "# Train_test split\n",
    "random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b3e7dc4ad741fc204e00f5d7c870c4f3f1d0310"
   },
   "source": [
    "# <a id='6'>6. XGBoost - RandomizedSearchCV to optimize hyperparameters</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25ea2f73bcbd891d95623f3de322236452c58d75"
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        \n",
    "        \n",
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n",
    "\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators' : [100, 200, 500, 750],\n",
    "        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n",
    "        'min_child_weight': [1, 5, 7, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 12]\n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "param_comb = 800\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_cfl, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=-1, cv=5, verbose=3, random_state=42)\n",
    "\n",
    "# Here we go\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "#----------------------------# random_search.fit(X, y)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19ea691d7cf7b37d12c28df1daf9c03aa69604e0"
   },
   "source": [
    "Remove \"#----------------------------#\" to lunch random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13c7bc3e83e56fb021b15862a4b3127b00175ef5"
   },
   "outputs": [],
   "source": [
    "#print('\\n All results:')\n",
    "#print(random_search.cv_results_)\n",
    "#print('\\n Best estimator:')\n",
    "#print(random_search.best_estimator_)\n",
    "#print('\\n Best accuracy for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "#print(random_search.best_score_ )\n",
    "#print('\\n Best hyperparameters:')\n",
    "#print(random_search.best_params_)\n",
    "#results = pd.DataFrame(random_search.cv_results_)\n",
    "#results.to_csv('xgb-random-grid-search-results-01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b390918f77cc9250ec184b013cfad0b71921df6d"
   },
   "source": [
    "\n",
    "\n",
    "**RESULT : **\n",
    "\n",
    "Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
    "       n_estimators=200, n_jobs=-1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=0.6)\n",
    "\n",
    " Best accuracy for 5-fold search with 800 parameter combinations:\n",
    "0.891156462585034\n",
    "\n",
    " Best hyperparameters:\n",
    "{'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 7, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 1.5, 'colsample_bytree': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "448e48609f713fc9eac15409018138656049dcca"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b1c816721a77c5eb63940ec14d6bbce8cdd08cd"
   },
   "source": [
    "# <a id='7'>7. XGBoost - Modeling with best hyperparameters = 89.11</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44a5cf497de23ece4be0faf61f7d3cf534c2edfd"
   },
   "source": [
    "## <a id='7.1'>7.1. XGBoost - Modeling and performance plot</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85b225a5e5b024339c3449afd934e815164b001b"
   },
   "outputs": [],
   "source": [
    "# xgb \n",
    "xgb_clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                           colsample_bytree=0.8, gamma=1.5, learning_rate=0.05,\n",
    "                           max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
    "                           n_estimators=200, n_jobs=-1, nthread=None,\n",
    "                           objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "                           reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "                           subsample=0.6)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "y_score = xgb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "model_performance_plot('xgb_clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93442a1d6dae9d0de6a34724e22a57645a10b773"
   },
   "source": [
    "## <a id='7.2'>7.2. XGBoost - Feature importance </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac2d9efb66f89dead68ed2d6079e8498ec8244d7"
   },
   "outputs": [],
   "source": [
    "features_imp(xgb_clf, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd40ff6d8c0b252283303ac91e2669e6c2b3291e"
   },
   "outputs": [],
   "source": [
    "#feature importance plot TOP 40\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_feature_importance(model):\n",
    "    tmp = pd.DataFrame({'Feature': list(data), 'Feature importance': model.feature_importances_})\n",
    "    tmp = tmp.sort_values(by='Feature importance',ascending=False).head(30)\n",
    "    plt.figure(figsize = (10,12))\n",
    "    plt.title('Top 30 - Features importance - XGBoost',fontsize=14)\n",
    "    s = sns.barplot(y='Feature',x='Feature importance',data=tmp, orient='h')\n",
    "    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "741b2cf4991aa647e7c47331aaeb45d771aa4d97"
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d55e2c0d3079b8730819908081bc225284ffb46"
   },
   "source": [
    "## <a id='7.3'>7.3. XGBoost - Cumulative gain curve</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d99faf6bbb4ec1e261ecb599040d7b80c22229c"
   },
   "outputs": [],
   "source": [
    "cum_gains_curve(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb4df284bf134f992dad689dcc296c8aaac7d1a4"
   },
   "source": [
    "## <a id='7.4'>7.4. XGBoost - Cross validation (5 folds)</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc6c077c24968c75ce53856eabe215d4dd6388b7"
   },
   "outputs": [],
   "source": [
    "# Cross val score\n",
    "cross_val_metrics(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d406e45e72d85b091d2bad1688b63fc88da3ff1"
   },
   "source": [
    "**Thank you all ! Merci Ã  tous ! :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
